{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content     emotion\n",
      "0  @tiffanylue i know  i was listenin to bad habi...       empty\n",
      "1  Layin n bed with a headache  ughhhh...waitin o...     sadness\n",
      "2                Funeral ceremony...gloomy friday...     sadness\n",
      "3               wants to hang out with friends SOON!  enthusiasm\n",
      "4  @dannycastillo We want to trade with someone w...     neutral\n",
      "5  Re-pinging @ghostridah14: why didn't you go to...       worry\n",
      "6  I should be sleep, but im not! thinking about ...     sadness\n",
      "7               Hmmm. http://www.djhero.com/ is down       worry\n",
      "8            @charviray Charlene my love. I miss you     sadness\n",
      "9         @kelcouch I'm sorry  at least it's Friday?     sadness\n",
      "emotion\n",
      "neutral       8638\n",
      "worry         8459\n",
      "happiness     5209\n",
      "sadness       5165\n",
      "love          3842\n",
      "surprise      2187\n",
      "fun           1776\n",
      "relief        1526\n",
      "hate          1323\n",
      "empty          827\n",
      "enthusiasm     759\n",
      "boredom        179\n",
      "anger          110\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('tweet_emotions.csv')\n",
    "# print(df.head(10))\n",
    "\n",
    "# Remove tweet_id\n",
    "df = df.drop(['tweet_id'], axis=1)\n",
    "# print(df.head(10))\n",
    "# Modify labels sentiment to emotion\n",
    "df = df.rename(columns={'sentiment': 'emotion'})\n",
    "# print(df.head(10))\n",
    "\n",
    "#Swap between columns\n",
    "df = df[['content', 'emotion']]\n",
    "print(df.head(10))\n",
    "print(df['emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content     emotion\n",
      "0  @tiffanylue i know  i was listenin to bad habi...       empty\n",
      "1  Layin n bed with a headache  ughhhh...waitin o...     sadness\n",
      "2                Funeral ceremony...gloomy friday...     sadness\n",
      "3               wants to hang out with friends SOON!  enthusiasm\n",
      "4  @dannycastillo We want to trade with someone w...     neutral\n",
      "5  Re-pinging @ghostridah14: why didn't you go to...       worry\n",
      "6  I should be sleep, but im not! thinking about ...     sadness\n",
      "7               Hmmm. http://www.djhero.com/ is down       worry\n",
      "8            @charviray Charlene my love. I miss you     sadness\n",
      "9         @kelcouch I'm sorry  at least it's Friday?     sadness\n",
      "emotion\n",
      "neutral       8638\n",
      "worry         8459\n",
      "happiness     7209\n",
      "sadness       5165\n",
      "love          3842\n",
      "surprise      2187\n",
      "anger         2110\n",
      "fear          1937\n",
      "fun           1776\n",
      "relief        1526\n",
      "hate          1323\n",
      "empty          827\n",
      "enthusiasm     759\n",
      "boredom        179\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Load data from Emotion_classify_data.csv\n",
    "df2 = pd.read_csv('Emotion_classify_Data.csv')\n",
    "# print(df2.head(10))\n",
    "\n",
    "#Show repartition of emotions in the dataset\n",
    "# print(df2['Emotion'].value_counts())\n",
    "\n",
    "#Change labels Emotion to emotion\n",
    "df2 = df2.rename(columns={'Emotion': 'emotion'})\n",
    "df2 = df2.rename(columns={'Comment': 'content'})\n",
    "\n",
    "#Change label joy to happiness\n",
    "df2['emotion'] = df2['emotion'].replace('joy', 'happiness')\n",
    "# print(df2.head(10))\n",
    "# print(df2['emotion'].value_counts())\n",
    "\n",
    "#Concatenate both datasets\n",
    "df_concat = pd.concat([df, df2], ignore_index=True)\n",
    "print(df_concat.head(10))\n",
    "print(df_concat['emotion'].value_counts())\n",
    "\n",
    "#Change labels to m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "happiness     13970\n",
      "sadness       10962\n",
      "neutral        8638\n",
      "worry          8459\n",
      "love           5483\n",
      "anger          4819\n",
      "fear           4310\n",
      "surprise       2906\n",
      "fun            1776\n",
      "relief         1526\n",
      "hate           1323\n",
      "empty           827\n",
      "enthusiasm      759\n",
      "boredom         179\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Merge all data from training.csv, test.csv and validation.csv\n",
    "df3 = pd.read_csv('training.csv')\n",
    "df4 = pd.read_csv('test.csv')\n",
    "df5 = pd.read_csv('validation.csv')\n",
    "df6 = pd.concat([df3,df4,df5])\n",
    "# print(df6.head(10))\n",
    "\n",
    "dict = {0 : 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'}\n",
    "\n",
    "#Replace numbers of label by emotions using the dictionary\n",
    "df6['label'] = df6['label'].replace(dict)\n",
    "# print(df6.head(10))\n",
    "\n",
    "#Change label text to content and label to emotion\n",
    "df6 = df6.rename(columns={'text': 'content'})\n",
    "df6 = df6.rename(columns={'label': 'emotion'})\n",
    "\n",
    "#Change joy to happiness\n",
    "df6['emotion'] = df6['emotion'].replace('joy', 'happiness')\n",
    "\n",
    "\n",
    "#Show repartition of emotions in the dataset\n",
    "# print(df6['emotion'].value_counts())\n",
    "\n",
    "#Concat both datasets\n",
    "df_final = pd.concat([df_concat, df6], ignore_index=True)\n",
    "print(df_final['emotion'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['empty' 'sadness' 'enthusiasm' 'neutral' 'worry' 'surprise' 'love' 'fun'\n",
      " 'hate' 'happiness' 'boredom' 'relief' 'anger']\n",
      "emotion\n",
      "neutral       8638\n",
      "worry         8459\n",
      "happiness     5209\n",
      "sadness       5165\n",
      "love          3842\n",
      "surprise      2187\n",
      "fun           1776\n",
      "relief        1526\n",
      "hate          1323\n",
      "empty          827\n",
      "enthusiasm     759\n",
      "boredom        179\n",
      "anger          110\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Show me all the diffrent sentiment\n",
    "print(df['emotion'].unique())\n",
    "\n",
    "#Show me the reparition of each sentiment\n",
    "print(df['emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LE VRAI CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admiration : 17131\n",
      "amusement : 9245\n",
      "anger : 8084\n",
      "annoyance : 13618\n",
      "approval : 17620\n",
      "caring : 5999\n",
      "confusion : 7359\n",
      "curiosity : 9692\n",
      "desire : 3817\n",
      "disappointment : 8469\n",
      "disapproval : 11424\n",
      "disgust : 5301\n",
      "embarrassment : 2476\n",
      "excitement : 5629\n",
      "fear : 3197\n",
      "gratitude : 11625\n",
      "grief : 673\n",
      "joy : 7983\n",
      "love : 8191\n",
      "nervousness : 1810\n",
      "optimism : 8715\n",
      "pride : 1302\n",
      "realization : 8785\n",
      "relief : 1289\n",
      "remorse : 2525\n",
      "sadness : 6758\n",
      "surprise : 5514\n",
      "neutral : 55298\n",
      "              text  admiration  amusement  anger  annoyance  approval  love  \\\n",
      "0  That game hurt.           0          0      0          0         0     0   \n",
      "\n",
      "   sadness  curiosity  joy  disappointment  \n",
      "0        1          0    0               0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#Read dataset from go_emotions_dataset.csv\n",
    "df_go = pd.read_csv('go_emotions_dataset.csv')\n",
    "# print(df_go.head(10))\n",
    "\n",
    "#Remove id and example_very_unclear\n",
    "df_go = df_go.drop(['id', 'example_very_unclear'], axis=1)\n",
    "# print(df_go.head(1))\n",
    "\n",
    "\n",
    "#Sum the colum admiration\n",
    "# print(df_go['admiration'].sum())\n",
    "#Do the same for all emotions using a for loop\n",
    "for i in range(1,len(df_go.columns)):\n",
    "    print(df_go.columns[i] + \" : \" + str(df_go[df_go.columns[i]].sum()))\n",
    "\n",
    "#Keep only 10 best emotions\n",
    "emotions_10 = ['text', 'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'love', 'sadness', 'curiosity', 'joy', 'disappointment']\n",
    "df_go = df_go[emotions_10]\n",
    "print(df_go.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/flo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# Remove all the duplicated values\n",
    "df_go = df_go.drop_duplicates()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "# print(df_go.head(10))\n",
    "#Remove all the stopwords\n",
    "df_go['text'] = df_go['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "# print(df_go.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
      "       'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
      "       'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
      "       'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n",
      "       'relief', 'remorse', 'sadness', 'surprise', 'neutral'],\n",
      "      dtype='object')\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "#show all emotions\n",
    "print(df_go.columns[1:])\n",
    "print(len(df_go.columns[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data input shape:  (123308,)\n",
      "Training Data output shape:  (123308, 28)\n",
      "Testing Data input shape:  (30827,)\n",
      "Testing Data output shape:  (30827, 28)\n"
     ]
    }
   ],
   "source": [
    "# Separate the data into content and labels\n",
    "X = df_go['text'].to_numpy()\n",
    "# print(X)\n",
    "\n",
    "# Convert each emotions to n\n",
    "y = df_go.iloc[:, 1:].to_numpy()\n",
    "# print(y)\n",
    "\n",
    "#Separate the data into training and testing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "print(\"Training Data input shape: \", X_train.shape)\n",
    "print(\"Training Data output shape: \", y_train.shape)\n",
    "print(\"Testing Data input shape: \", X_test.shape)\n",
    "print(\"Testing Data output shape: \", y_test.shape)\n",
    "#Use only half of X_train\n",
    "X_train = X_train[:int(len(X_train)/2)]\n",
    "y_train = y_train[:int(len(y_train)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:  27519\n",
      "Number of Documents:  61654\n",
      "Number of Words:  27518\n"
     ]
    }
   ],
   "source": [
    "#Tokenize the data\n",
    "oov_tok = \"UNK\"\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "vocab_size = len(tokenizer.index_word) + 1\n",
    "print(\"Vocabulary Size: \", vocab_size)\n",
    "print(\"Number of Documents: \", tokenizer.document_count)\n",
    "print(\"Number of Words: \", len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'super': 550,\n",
       "             'hard': 1222,\n",
       "             'training': 57,\n",
       "             'would': 4977,\n",
       "             'imagine': 587,\n",
       "             'i': 36401,\n",
       "             'weeks': 208,\n",
       "             'past': 307,\n",
       "             'girl': 620,\n",
       "             'maybe': 1404,\n",
       "             'think': 4280,\n",
       "             'mercury': 4,\n",
       "             'read': 969,\n",
       "             'news': 473,\n",
       "             'sfgate': 1,\n",
       "             \"it's\": 2849,\n",
       "             'well': 2759,\n",
       "             'you': 7482,\n",
       "             'matter': 434,\n",
       "             'anyway': 331,\n",
       "             'compliments': 12,\n",
       "             'help': 1141,\n",
       "             'ignore': 113,\n",
       "             'okay': 550,\n",
       "             'really': 4244,\n",
       "             'true': 852,\n",
       "             '3': 1026,\n",
       "             'checked': 96,\n",
       "             'omg': 567,\n",
       "             'so': 2247,\n",
       "             'mostly': 183,\n",
       "             'name': 17285,\n",
       "             'haha': 945,\n",
       "             'star': 142,\n",
       "             'right': 2607,\n",
       "             'fucking': 1103,\n",
       "             'game': 1695,\n",
       "             'like': 9792,\n",
       "             'sucks': 468,\n",
       "             'link': 249,\n",
       "             'thanks': 2676,\n",
       "             \"i'm\": 5301,\n",
       "             'reddit': 634,\n",
       "             'adding': 41,\n",
       "             'savvy': 5,\n",
       "             'stuff': 602,\n",
       "             'pls': 54,\n",
       "             'goal': 190,\n",
       "             'mistake': 184,\n",
       "             'ball': 184,\n",
       "             'damn': 1383,\n",
       "             'make': 2479,\n",
       "             'enemy': 44,\n",
       "             'hate': 1303,\n",
       "             'use': 967,\n",
       "             'hands': 215,\n",
       "             'outside': 248,\n",
       "             'keep': 1168,\n",
       "             'keepers': 4,\n",
       "             'keeps': 145,\n",
       "             'strong': 306,\n",
       "             'captain': 25,\n",
       "             'ego': 41,\n",
       "             'going': 2218,\n",
       "             'inflated': 11,\n",
       "             'whatever': 261,\n",
       "             'extra': 148,\n",
       "             'sox': 10,\n",
       "             'offer': 121,\n",
       "             'million': 107,\n",
       "             'wouldn‚Äôt': 202,\n",
       "             '20': 353,\n",
       "             'white': 215,\n",
       "             'what': 2482,\n",
       "             'yt': 26,\n",
       "             'drama': 75,\n",
       "             'sorry': 2250,\n",
       "             'celebs': 4,\n",
       "             'happened': 583,\n",
       "             'draw': 55,\n",
       "             'learn': 283,\n",
       "             'book': 219,\n",
       "             \"there's\": 635,\n",
       "             'comic': 54,\n",
       "             'better': 2137,\n",
       "             'it': 7395,\n",
       "             'write': 154,\n",
       "             'do': 1197,\n",
       "             'way': 2470,\n",
       "             'something': 1798,\n",
       "             'posting': 208,\n",
       "             'need': 1847,\n",
       "             'run': 411,\n",
       "             'taking': 480,\n",
       "             'always': 1606,\n",
       "             'sub': 863,\n",
       "             'best': 1744,\n",
       "             'therapist': 95,\n",
       "             'hope': 2169,\n",
       "             'physician': 11,\n",
       "             'advice': 322,\n",
       "             'people': 4991,\n",
       "             'no': 2548,\n",
       "             'applies': 20,\n",
       "             'placebos': 3,\n",
       "             'shit': 1157,\n",
       "             'working': 317,\n",
       "             'say': 1929,\n",
       "             'same': 554,\n",
       "             'offense': 91,\n",
       "             'likely': 260,\n",
       "             'unfortunately': 335,\n",
       "             'good': 5013,\n",
       "             'at': 618,\n",
       "             'cushioning': 2,\n",
       "             'least': 1036,\n",
       "             \"that'\": 3,\n",
       "             'arrows': 10,\n",
       "             'following': 66,\n",
       "             'death': 294,\n",
       "             'dope': 32,\n",
       "             'bats': 13,\n",
       "             'red': 285,\n",
       "             'bunch': 167,\n",
       "             'great': 1942,\n",
       "             'not': 2303,\n",
       "             'admit': 104,\n",
       "             'humble': 19,\n",
       "             'many': 1093,\n",
       "             'cancering': 4,\n",
       "             'glad': 1432,\n",
       "             'srs': 15,\n",
       "             'stop': 1074,\n",
       "             'fold': 10,\n",
       "             'tips': 42,\n",
       "             'could': 1989,\n",
       "             'wrench': 9,\n",
       "             'hulk': 5,\n",
       "             'once': 195,\n",
       "             'finger': 49,\n",
       "             'measure': 35,\n",
       "             'made': 1457,\n",
       "             'experience': 310,\n",
       "             'disgust': 16,\n",
       "             \"i've\": 1606,\n",
       "             'never': 2605,\n",
       "             'one': 5191,\n",
       "             'schadenfreude': 8,\n",
       "             'has': 134,\n",
       "             'article': 269,\n",
       "             'equal': 38,\n",
       "             'much': 2844,\n",
       "             'lot': 1184,\n",
       "             'greatest': 76,\n",
       "             'however': 121,\n",
       "             'mister': 12,\n",
       "             'actually': 1937,\n",
       "             'human': 257,\n",
       "             'exist': 171,\n",
       "             'means': 374,\n",
       "             'thank': 2096,\n",
       "             'compliment': 30,\n",
       "             'ever': 1415,\n",
       "             'interesting': 852,\n",
       "             'sounds': 1016,\n",
       "             'this': 6329,\n",
       "             'san': 21,\n",
       "             'waifu': 15,\n",
       "             'favorite': 689,\n",
       "             'yes': 1466,\n",
       "             'picasso': 3,\n",
       "             'ah': 532,\n",
       "             'portland': 11,\n",
       "             'only': 303,\n",
       "             'joking': 71,\n",
       "             'queen': 105,\n",
       "             'several': 95,\n",
       "             'points': 212,\n",
       "             'uk': 101,\n",
       "             'must': 670,\n",
       "             'thought': 1756,\n",
       "             'cool': 992,\n",
       "             'height': 31,\n",
       "             'career': 147,\n",
       "             'nicer': 40,\n",
       "             'looking': 766,\n",
       "             'ughhh': 2,\n",
       "             'whyyyyy': 3,\n",
       "             'exact': 162,\n",
       "             'displayed': 5,\n",
       "             'mine': 348,\n",
       "             'bro': 389,\n",
       "             'type': 262,\n",
       "             'leave': 485,\n",
       "             'behavior': 147,\n",
       "             'drink': 159,\n",
       "             'hand': 246,\n",
       "             'woulda': 12,\n",
       "             'sneezed': 4,\n",
       "             'launched': 5,\n",
       "             'behind': 213,\n",
       "             'mah': 28,\n",
       "             'gawd': 14,\n",
       "             'oh': 2817,\n",
       "             'realize': 406,\n",
       "             'away': 770,\n",
       "             'fail': 92,\n",
       "             'yeah': 2442,\n",
       "             'know': 4247,\n",
       "             'tearing': 13,\n",
       "             'bones': 33,\n",
       "             'flesh': 23,\n",
       "             'the': 4832,\n",
       "             'relief': 39,\n",
       "             'world': 709,\n",
       "             'cat': 264,\n",
       "             'they‚Äôre': 379,\n",
       "             'physically': 70,\n",
       "             'whole': 635,\n",
       "             'heart': 360,\n",
       "             'raping': 26,\n",
       "             'thing': 2104,\n",
       "             'mebtally': 2,\n",
       "             'hurt': 372,\n",
       "             'someone': 1994,\n",
       "             'wouldnt': 79,\n",
       "             'explaining': 59,\n",
       "             'person': 1062,\n",
       "             'unpopular': 43,\n",
       "             'time': 3375,\n",
       "             'wins': 112,\n",
       "             'sure': 1835,\n",
       "             'mean': 1424,\n",
       "             'tea': 50,\n",
       "             'air': 96,\n",
       "             'top': 438,\n",
       "             'robbed': 18,\n",
       "             'even': 3017,\n",
       "             'ee': 7,\n",
       "             'see': 3291,\n",
       "             'bums': 4,\n",
       "             'don‚Äôt': 1967,\n",
       "             'dead': 362,\n",
       "             'little': 1115,\n",
       "             'bit': 641,\n",
       "             'confused': 191,\n",
       "             'guys': 943,\n",
       "             'ask': 425,\n",
       "             'traps': 6,\n",
       "             'tiki': 5,\n",
       "             '1st': 94,\n",
       "             'yesterday': 176,\n",
       "             'coming': 476,\n",
       "             'record': 126,\n",
       "             'cowboys': 29,\n",
       "             'rushing': 9,\n",
       "             'end': 754,\n",
       "             'breaking': 104,\n",
       "             'feels': 469,\n",
       "             'believe': 971,\n",
       "             'era': 32,\n",
       "             'win': 548,\n",
       "             'can‚Äôt': 798,\n",
       "             'saw': 600,\n",
       "             'overdue': 9,\n",
       "             'point': 1067,\n",
       "             'getting': 1305,\n",
       "             \"he's\": 1254,\n",
       "             '3rd': 85,\n",
       "             'now': 1961,\n",
       "             'period': 103,\n",
       "             'loss': 252,\n",
       "             'philosophies': 11,\n",
       "             'rejuvenated': 6,\n",
       "             'older': 172,\n",
       "             'him': 1057,\n",
       "             'conor': 2,\n",
       "             'admire': 17,\n",
       "             'though': 1782,\n",
       "             'khabib': 2,\n",
       "             'fan': 465,\n",
       "             'hopefully': 300,\n",
       "             'im': 740,\n",
       "             'dude': 1124,\n",
       "             'cheers': 237,\n",
       "             'upvoted': 57,\n",
       "             'love': 4740,\n",
       "             'itd': 7,\n",
       "             'incredible': 114,\n",
       "             'left': 668,\n",
       "             'unassigned': 4,\n",
       "             'clg': 4,\n",
       "             'especially': 411,\n",
       "             'they': 1778,\n",
       "             'friends': 678,\n",
       "             'biofrost': 2,\n",
       "             'still': 2759,\n",
       "             'feel': 2338,\n",
       "             'last': 1259,\n",
       "             'reposts': 13,\n",
       "             'literally': 735,\n",
       "             'week': 462,\n",
       "             'lads': 11,\n",
       "             'adventurous': 9,\n",
       "             'sites': 33,\n",
       "             'granddaddy': 2,\n",
       "             'boys': 163,\n",
       "             'girls': 287,\n",
       "             'can': 644,\n",
       "             'rom': 4,\n",
       "             'check': 384,\n",
       "             'theme': 34,\n",
       "             'but': 2010,\n",
       "             'kinda': 493,\n",
       "             'party': 234,\n",
       "             'plenty': 148,\n",
       "             'why': 1160,\n",
       "             'prior': 34,\n",
       "             'sex': 436,\n",
       "             'me': 2254,\n",
       "             'upside': 18,\n",
       "             'talk': 585,\n",
       "             'that': 4850,\n",
       "             'beyond': 86,\n",
       "             'there': 1491,\n",
       "             'downside': 6,\n",
       "             'lives': 133,\n",
       "             'mmhmm': 2,\n",
       "             'said': 1331,\n",
       "             'ye': 35,\n",
       "             'get': 5375,\n",
       "             'player': 257,\n",
       "             'for': 744,\n",
       "             'possession': 21,\n",
       "             'bad': 2562,\n",
       "             'crazy': 588,\n",
       "             'lines': 119,\n",
       "             '5': 660,\n",
       "             'shirt': 108,\n",
       "             'wear': 171,\n",
       "             'annoying': 146,\n",
       "             'comfortable': 76,\n",
       "             'jealous': 157,\n",
       "             'shirty': 2,\n",
       "             'large': 88,\n",
       "             'climb': 10,\n",
       "             'comfy': 22,\n",
       "             'an': 130,\n",
       "             'found': 513,\n",
       "             'mrs': 16,\n",
       "             'times': 683,\n",
       "             'frizzle': 4,\n",
       "             'blow': 38,\n",
       "             'feeling': 503,\n",
       "             'knew': 370,\n",
       "             'up': 927,\n",
       "             'idea': 786,\n",
       "             'tax': 124,\n",
       "             'anyone': 935,\n",
       "             'stupid': 765,\n",
       "             'he‚Äôs': 615,\n",
       "             'shooting': 99,\n",
       "             'scared': 226,\n",
       "             'spot': 133,\n",
       "             'confidence': 83,\n",
       "             'expand': 23,\n",
       "             'guess': 931,\n",
       "             'huh': 216,\n",
       "             'miss': 437,\n",
       "             'day': 1649,\n",
       "             'ok': 892,\n",
       "             'nice': 1240,\n",
       "             'have': 738,\n",
       "             'discussed': 25,\n",
       "             'topic': 76,\n",
       "             'we': 1433,\n",
       "             'wish': 1114,\n",
       "             'go': 2655,\n",
       "             'earring': 1,\n",
       "             'listen': 211,\n",
       "             'golden': 69,\n",
       "             'gotta': 471,\n",
       "             'finally': 307,\n",
       "             'back': 2066,\n",
       "             'take': 1569,\n",
       "             'chance': 328,\n",
       "             'please': 895,\n",
       "             'adorable': 110,\n",
       "             'sweet': 333,\n",
       "             'possibly': 128,\n",
       "             'aware': 126,\n",
       "             'of': 446,\n",
       "             'his': 307,\n",
       "             'didnt': 253,\n",
       "             'video': 709,\n",
       "             'bust': 12,\n",
       "             'curious': 254,\n",
       "             'natty': 27,\n",
       "             'personally': 257,\n",
       "             'is': 1829,\n",
       "             'hats': 29,\n",
       "             'iq': 68,\n",
       "             '1': 723,\n",
       "             'increase': 43,\n",
       "             'just': 1520,\n",
       "             'sad': 724,\n",
       "             'actual': 270,\n",
       "             'spend': 163,\n",
       "             '10': 504,\n",
       "             \"that's\": 3283,\n",
       "             'understand': 787,\n",
       "             'app': 116,\n",
       "             \"you're\": 785,\n",
       "             'undeveloped': 2,\n",
       "             'masculinity': 28,\n",
       "             'defending': 40,\n",
       "             'disingenuous': 23,\n",
       "             'neckbeards': 6,\n",
       "             'cunt': 54,\n",
       "             'deformed': 4,\n",
       "             'droves': 2,\n",
       "             'come': 967,\n",
       "             'tell': 989,\n",
       "             'gots': 3,\n",
       "             'taken': 178,\n",
       "             'child': 374,\n",
       "             'worse': 662,\n",
       "             'life‚Äôs': 10,\n",
       "             'done': 750,\n",
       "             'short': 199,\n",
       "             'insane': 217,\n",
       "             'correct': 228,\n",
       "             'latter': 16,\n",
       "             'metric': 17,\n",
       "             'system': 192,\n",
       "             'probably': 1425,\n",
       "             'realistic': 50,\n",
       "             'throw': 173,\n",
       "             'fellow': 160,\n",
       "             'hello': 89,\n",
       "             'lions': 50,\n",
       "             'nashville': 15,\n",
       "             'seen': 970,\n",
       "             'team': 740,\n",
       "             'laziest': 11,\n",
       "             'that‚Äôs': 1663,\n",
       "             'takes': 289,\n",
       "             'practiced': 9,\n",
       "             'slower': 16,\n",
       "             'calculation': 3,\n",
       "             'it‚Äôs': 2478,\n",
       "             'and': 2296,\n",
       "             'speculation': 23,\n",
       "             'tbf': 23,\n",
       "             'look': 1649,\n",
       "             'net': 60,\n",
       "             'clears': 4,\n",
       "             'hehe': 15,\n",
       "             'couldn‚Äôt': 151,\n",
       "             'eeeee': 3,\n",
       "             'busted': 19,\n",
       "             'rich': 167,\n",
       "             'high': 575,\n",
       "             'complaining': 75,\n",
       "             'panel': 26,\n",
       "             'guy': 1541,\n",
       "             'us': 1554,\n",
       "             'rest': 353,\n",
       "             'stacked': 15,\n",
       "             'rhetoric': 11,\n",
       "             'wut': 22,\n",
       "             'lol': 3131,\n",
       "             'extremely': 214,\n",
       "             'ignorant': 143,\n",
       "             'ruined': 97,\n",
       "             'himself': 69,\n",
       "             'owe': 43,\n",
       "             'nothing': 1053,\n",
       "             'he': 1833,\n",
       "             'lucky': 234,\n",
       "             'reach': 65,\n",
       "             'op': 537,\n",
       "             'choose': 126,\n",
       "             'friend': 750,\n",
       "             'happiest': 22,\n",
       "             'u': 573,\n",
       "             'since': 838,\n",
       "             'smile': 181,\n",
       "             'üíõ': 3,\n",
       "             '6': 351,\n",
       "             'old': 1151,\n",
       "             'she‚Äôs': 305,\n",
       "             'sees': 56,\n",
       "             'light': 139,\n",
       "             'sometime': 30,\n",
       "             'months': 309,\n",
       "             'defect': 5,\n",
       "             'baby': 343,\n",
       "             'presidential': 14,\n",
       "             'rationalizing': 4,\n",
       "             'dictatorship': 9,\n",
       "             'amounts': 28,\n",
       "             'essentially': 34,\n",
       "             'with': 421,\n",
       "             'valid': 65,\n",
       "             'work': 1419,\n",
       "             'completely': 399,\n",
       "             'school': 540,\n",
       "             'helped': 155,\n",
       "             'learned': 160,\n",
       "             'soap': 19,\n",
       "             'ton': 69,\n",
       "             'medical': 121,\n",
       "             '1749485': 2,\n",
       "             'lmao': 685,\n",
       "             'cut': 247,\n",
       "             'seem': 486,\n",
       "             'adjusted': 10,\n",
       "             'individual': 67,\n",
       "             'empire': 47,\n",
       "             'west': 89,\n",
       "             'games': 515,\n",
       "             'sourcebook': 4,\n",
       "             'imperial': 9,\n",
       "             'show': 756,\n",
       "             'regime': 11,\n",
       "             'was': 611,\n",
       "             'awful': 473,\n",
       "             'man': 2182,\n",
       "             'likewise': 5,\n",
       "             'hardest': 56,\n",
       "             'wasn‚Äôt': 245,\n",
       "             'often': 252,\n",
       "             'forgive': 51,\n",
       "             'peace': 116,\n",
       "             'tap': 17,\n",
       "             'trigglypuff': 2,\n",
       "             'looks': 1588,\n",
       "             'she': 1196,\n",
       "             'push': 77,\n",
       "             'using': 403,\n",
       "             'platforms': 16,\n",
       "             'private': 85,\n",
       "             'vile': 24,\n",
       "             'indoctrination': 4,\n",
       "             'companies': 43,\n",
       "             'act': 187,\n",
       "             'state': 304,\n",
       "             'less': 605,\n",
       "             'hot': 347,\n",
       "             'ending': 136,\n",
       "             'thick': 50,\n",
       "             \"didn't\": 220,\n",
       "             'snow': 83,\n",
       "             'badly': 126,\n",
       "             'either': 657,\n",
       "             'concerts': 9,\n",
       "             'houseparty': 4,\n",
       "             'bar': 114,\n",
       "             'parties': 59,\n",
       "             's„Éé': 2,\n",
       "             '„Çú„Éé': 2,\n",
       "             'dropped': 88,\n",
       "             '„Çú': 2,\n",
       "             'center': 60,\n",
       "             'wanted': 509,\n",
       "             'groan': 6,\n",
       "             'reveal': 24,\n",
       "             'thinking': 507,\n",
       "             'convention': 18,\n",
       "             'sized': 29,\n",
       "             'coyotes': 13,\n",
       "             'sick': 293,\n",
       "             'slaughtered': 12,\n",
       "             'fault': 186,\n",
       "             'hey': 559,\n",
       "             'worried': 266,\n",
       "             'understands': 18,\n",
       "             'tobias': 3,\n",
       "             'damnit': 40,\n",
       "             'opens': 30,\n",
       "             'summer': 125,\n",
       "             'glorious': 58,\n",
       "             'august': 14,\n",
       "             'camp': 28,\n",
       "             'free': 532,\n",
       "             'football': 162,\n",
       "             'sports': 92,\n",
       "             'again': 586,\n",
       "             'download': 12,\n",
       "             'ivan': 1,\n",
       "             'aka': 10,\n",
       "             'vs': 145,\n",
       "             'v': 58,\n",
       "             'religion': 377,\n",
       "             'exciting': 54,\n",
       "             'definition': 70,\n",
       "             'alyosha': 1,\n",
       "             'different': 605,\n",
       "             'atheism': 13,\n",
       "             'also': 2101,\n",
       "             'in': 1007,\n",
       "             'ditched': 4,\n",
       "             'girlfriend': 115,\n",
       "             'got': 2639,\n",
       "             'noticed': 257,\n",
       "             'winners': 10,\n",
       "             'tomato': 11,\n",
       "             'burst': 23,\n",
       "             'bubble': 41,\n",
       "             'dodges': 12,\n",
       "             'history': 272,\n",
       "             'incoming': 10,\n",
       "             'fast': 222,\n",
       "             'big': 843,\n",
       "             'downhill': 22,\n",
       "             'supporter': 30,\n",
       "             '99': 56,\n",
       "             'open': 335,\n",
       "             'looked': 298,\n",
       "             'dear': 100,\n",
       "             'wine': 64,\n",
       "             'wasted': 42,\n",
       "             'sip': 10,\n",
       "             'out': 968,\n",
       "             'earlier': 101,\n",
       "             'play': 966,\n",
       "             'didn‚Äôt': 773,\n",
       "             'season': 634,\n",
       "             'riding': 36,\n",
       "             'powell': 5,\n",
       "             'a': 1198,\n",
       "             'bicycle': 7,\n",
       "             'dae': 8,\n",
       "             'anime': 46,\n",
       "             'to': 853,\n",
       "             'updoots': 7,\n",
       "             'bs': 84,\n",
       "             'meritocracy': 9,\n",
       "             'gtfo': 21,\n",
       "             'aa': 16,\n",
       "             'fuckyoukaren': 3,\n",
       "             'joke': 602,\n",
       "             'r': 822,\n",
       "             'happy': 1510,\n",
       "             'year': 1464,\n",
       "             'new': 1357,\n",
       "             'solve': 42,\n",
       "             'doesnt': 141,\n",
       "             'removes': 6,\n",
       "             'problem': 773,\n",
       "             'strongest': 17,\n",
       "             'horrible': 402,\n",
       "             'tool': 76,\n",
       "             'birthday': 175,\n",
       "             'signing': 56,\n",
       "             'remember': 738,\n",
       "             'pledge': 7,\n",
       "             'pledged': 2,\n",
       "             'truth': 206,\n",
       "             'sir': 111,\n",
       "             'forget': 278,\n",
       "             'beer': 115,\n",
       "             'yourself': 271,\n",
       "             'waste': 187,\n",
       "             'funny': 755,\n",
       "             'separation': 11,\n",
       "             'powers': 33,\n",
       "             'federal': 62,\n",
       "             'bavaria': 2,\n",
       "             'vote': 199,\n",
       "             'systems': 26,\n",
       "             'telling': 213,\n",
       "             'parliamentary': 2,\n",
       "             'executive': 10,\n",
       "             'special': 163,\n",
       "             '2019': 133,\n",
       "             'seriously': 454,\n",
       "             'community': 169,\n",
       "             'everyone': 1186,\n",
       "             'newyorkmets': 4,\n",
       "             'series': 162,\n",
       "             \"let's\": 344,\n",
       "             'makes': 1597,\n",
       "             'place': 668,\n",
       "             'fighting': 142,\n",
       "             'internet': 326,\n",
       "             'closely': 17,\n",
       "             'reason': 668,\n",
       "             'boycotted': 2,\n",
       "             'election': 63,\n",
       "             'opponents': 23,\n",
       "             'opposition': 20,\n",
       "             '2018': 71,\n",
       "             'sexuality': 33,\n",
       "             'stopping': 49,\n",
       "             'bi': 25,\n",
       "             'destructive': 9,\n",
       "             'applied': 28,\n",
       "             'self': 344,\n",
       "             'if': 2198,\n",
       "             'seems': 914,\n",
       "             'stupidest': 16,\n",
       "             'want': 2561,\n",
       "             'comments': 408,\n",
       "             'let': 861,\n",
       "             'character': 271,\n",
       "             'spam': 65,\n",
       "             'stand': 217,\n",
       "             'channels': 11,\n",
       "             'youtube': 213,\n",
       "             'terrible': 650,\n",
       "             \"can't\": 1705,\n",
       "             'dinner': 68,\n",
       "             'screens': 15,\n",
       "             'turned': 163,\n",
       "             'overstimulation': 4,\n",
       "             'technology': 33,\n",
       "             'sleep': 165,\n",
       "             'similar': 227,\n",
       "             'woke': 61,\n",
       "             'incase': 4,\n",
       "             'follow': 157,\n",
       "             'gyno': 3,\n",
       "             'happen': 508,\n",
       "             'sometimes': 478,\n",
       "             'gotcha': 67,\n",
       "             'congrats': 294,\n",
       "             'single': 329,\n",
       "             'dont': 786,\n",
       "             'relationship': 302,\n",
       "             'creep': 37,\n",
       "             'put': 811,\n",
       "             'because': 691,\n",
       "             'young': 324,\n",
       "             'rub': 22,\n",
       "             'thieves': 9,\n",
       "             'ankle': 33,\n",
       "             'fixes': 9,\n",
       "             'everything': 698,\n",
       "             'living‚Ñ¢Ô∏è': 4,\n",
       "             'ftfy': 46,\n",
       "             \"guy's\": 25,\n",
       "             'hair': 268,\n",
       "             'gods': 63,\n",
       "             'bible': 40,\n",
       "             'selfish': 79,\n",
       "             'acknowledges': 8,\n",
       "             'reasons': 117,\n",
       "             'weird': 1037,\n",
       "             'we‚Äôre': 208,\n",
       "             'part': 812,\n",
       "             'kind': 831,\n",
       "             'champion': 16,\n",
       "             'emotions': 72,\n",
       "             'reigning': 3,\n",
       "             'strangers': 45,\n",
       "             'doctor': 152,\n",
       "             'hoping': 258,\n",
       "             'absolutely': 515,\n",
       "             'beautiful': 466,\n",
       "             'story': 557,\n",
       "             'too': 1800,\n",
       "             'born': 115,\n",
       "             'pregnancy': 20,\n",
       "             'mom': 389,\n",
       "             'weirdness': 9,\n",
       "             'smaller': 48,\n",
       "             'damages': 10,\n",
       "             'property': 75,\n",
       "             'sue': 38,\n",
       "             'comp': 24,\n",
       "             'cover': 94,\n",
       "             'given': 261,\n",
       "             'gets': 734,\n",
       "             'steps': 62,\n",
       "             'shots': 81,\n",
       "             '2': 1174,\n",
       "             'head': 479,\n",
       "             'things': 1330,\n",
       "             'stay': 509,\n",
       "             'slight': 16,\n",
       "             'might': 923,\n",
       "             'discomfort': 7,\n",
       "             'uncle': 47,\n",
       "             'hero': 112,\n",
       "             'humour': 25,\n",
       "             'obvious': 156,\n",
       "             'needed': 284,\n",
       "             'add': 175,\n",
       "             'pretty': 1912,\n",
       "             'timing': 39,\n",
       "             'agree': 652,\n",
       "             'kadri': 5,\n",
       "             'pool': 62,\n",
       "             'holy': 337,\n",
       "             'my': 1994,\n",
       "             'i‚Äôm': 2736,\n",
       "             'i‚Äôll': 372,\n",
       "             'background': 91,\n",
       "             'doesn‚Äôt': 474,\n",
       "             'phone': 285,\n",
       "             'care': 718,\n",
       "             'brexit': 62,\n",
       "             'viable': 7,\n",
       "             'ends': 107,\n",
       "             'anyways': 128,\n",
       "             'contracts': 20,\n",
       "             'staying': 60,\n",
       "             'wwe': 15,\n",
       "             'other': 176,\n",
       "             'give': 1082,\n",
       "             'money': 729,\n",
       "             'peoples': 23,\n",
       "             'worst': 641,\n",
       "             'recessed': 7,\n",
       "             'fuck': 1231,\n",
       "             'lower': 78,\n",
       "             'how': 1144,\n",
       "             'decent': 156,\n",
       "             'face': 567,\n",
       "             'chin': 26,\n",
       "             'boi': 51,\n",
       "             'goes': 395,\n",
       "             'kidding': 99,\n",
       "             'cute': 413,\n",
       "             'religiousfruitcake': 3,\n",
       "             'posted': 321,\n",
       "             'x': 111,\n",
       "             'contact': 102,\n",
       "             'wow': 1567,\n",
       "             'marry': 53,\n",
       "             'stbx': 9,\n",
       "             'plant': 44,\n",
       "             'wildflowers': 3,\n",
       "             'local': 127,\n",
       "             'pollinators': 3,\n",
       "             'album': 92,\n",
       "             'excited': 268,\n",
       "             'bop': 15,\n",
       "             'fall': 196,\n",
       "             'monster': 95,\n",
       "             'ex': 173,\n",
       "             'films': 24,\n",
       "             'real': 1081,\n",
       "             'risks': 13,\n",
       "             'lack': 138,\n",
       "             'animal': 90,\n",
       "             'fart': 29,\n",
       "             'implications': 10,\n",
       "             'bravo': 13,\n",
       "             'nowadays': 49,\n",
       "             'legit': 110,\n",
       "             'talked': 59,\n",
       "             'sane': 30,\n",
       "             'watching': 472,\n",
       "             'yrs': 22,\n",
       "             'met': 141,\n",
       "             'bf': 39,\n",
       "             'adverts': 8,\n",
       "             'upcoming': 14,\n",
       "             'wondering': 211,\n",
       "             'second': 573,\n",
       "             'deal': 429,\n",
       "             'find': 1276,\n",
       "             \"what's\": 403,\n",
       "             'pic': 140,\n",
       "             'notley': 3,\n",
       "             'helps': 147,\n",
       "             'grow': 144,\n",
       "             'governance': 4,\n",
       "             'economy': 39,\n",
       "             'nomics': 3,\n",
       "             'jail': 98,\n",
       "             'scene': 155,\n",
       "             'hugs': 103,\n",
       "             'platonic': 7,\n",
       "             'date': 250,\n",
       "             'explained': 34,\n",
       "             'allowed': 181,\n",
       "             \"she'd\": 43,\n",
       "             'cry': 178,\n",
       "             'otherwise': 177,\n",
       "             'used': 733,\n",
       "             'stick': 160,\n",
       "             'upvote': 213,\n",
       "             'legally': 44,\n",
       "             'shoes': 100,\n",
       "             'lost': 481,\n",
       "             'respond': 58,\n",
       "             'dog': 412,\n",
       "             'tinder': 43,\n",
       "             'picture': 307,\n",
       "             'lots': 177,\n",
       "             'be': 549,\n",
       "             'careful': 100,\n",
       "             'students': 81,\n",
       "             'rationale': 16,\n",
       "             'covington': 2,\n",
       "             'them': 1060,\n",
       "             'exes': 12,\n",
       "             'overcome': 21,\n",
       "             'nah': 326,\n",
       "             'mildlyinteresting': 4,\n",
       "             'i‚Äôd': 412,\n",
       "             'reasonable': 93,\n",
       "             'enough': 938,\n",
       "             'suggests': 19,\n",
       "             'works': 351,\n",
       "             'anecdote': 18,\n",
       "             'example': 167,\n",
       "             'treasure': 29,\n",
       "             'excerpt': 6,\n",
       "             'from': 307,\n",
       "             'surrounded': 30,\n",
       "             'kinds': 46,\n",
       "             'perfect': 291,\n",
       "             '‚Äúparties‚Äù': 3,\n",
       "             'before': 328,\n",
       "             'start': 637,\n",
       "             'legs': 91,\n",
       "             'embarrassed': 51,\n",
       "             'obvi': 3,\n",
       "             'next': 833,\n",
       "             'names': 90,\n",
       "             'are': 940,\n",
       "             'heard': 622,\n",
       "             \"'x'\": 1,\n",
       "             'years': 1459,\n",
       "             'another': 823,\n",
       "             'call': 660,\n",
       "             'laid': 62,\n",
       "             'hog': 16,\n",
       "             'hook': 47,\n",
       "             'over': 198,\n",
       "             'shot': 324,\n",
       "             'combo': 45,\n",
       "             'forward': 200,\n",
       "             'pm': 100,\n",
       "             'needs': 564,\n",
       "             'went': 597,\n",
       "             'night': 414,\n",
       "             'anybody': 106,\n",
       "             'theaters': 10,\n",
       "             'rewatched': 16,\n",
       "             'coma': 15,\n",
       "             'consent': 44,\n",
       "             'thats': 445,\n",
       "             'pig': 30,\n",
       "             'i‚Äôve': 729,\n",
       "             'share': 205,\n",
       "             'whistle': 5,\n",
       "             'pie': 14,\n",
       "             'first': 1524,\n",
       "             'kids': 732,\n",
       "             'ü§î': 65,\n",
       "             'fp': 5,\n",
       "             'movie': 381,\n",
       "             'her': 816,\n",
       "             'cos': 18,\n",
       "             'pan': 27,\n",
       "             'exactly': 681,\n",
       "             'warm': 123,\n",
       "             'colors': 31,\n",
       "             'babey': 2,\n",
       "             'willing': 132,\n",
       "             'fleece': 2,\n",
       "             'pull': 169,\n",
       "             'trigger': 52,\n",
       "             'gm': 37,\n",
       "             'moment': 303,\n",
       "             'involve': 19,\n",
       "             'landlord': 19,\n",
       "             'roomie': 1,\n",
       "             'stressed': 29,\n",
       "             'ya': 359,\n",
       "             'alot': 69,\n",
       "             'shes': 84,\n",
       "             'rewind': 19,\n",
       "             'tyranny': 10,\n",
       "             'spamming': 25,\n",
       "             'yoir': 4,\n",
       "             'level': 294,\n",
       "             'abstraction': 4,\n",
       "             'sense': 526,\n",
       "             'ha': 175,\n",
       "             'am': 278,\n",
       "             'cash': 73,\n",
       "             'our': 155,\n",
       "             'embarrassment': 33,\n",
       "             'bottom': 164,\n",
       "             'style': 100,\n",
       "             'league': 184,\n",
       "             'performance': 80,\n",
       "             'volume': 44,\n",
       "             'instead': 420,\n",
       "             'music': 239,\n",
       "             'enjoy': 588,\n",
       "             'ear': 38,\n",
       "             'wondered': 78,\n",
       "             ...})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer.word_counts\n",
    "tokenizer.word_docs\n",
    "# Clean all empty words like : a, the, and, etc...\n",
    "#Show the 10 most common words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2143, 3006, 716]\n"
     ]
    }
   ],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "print(train_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 200\n",
    "X_train = pad_sequences(train_sequences, maxlen=sequence_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(test_sequences, maxlen=sequence_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM (L'ANGOISSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "emdedding_dim = 16\n",
    "model.add(Embedding(vocab_size, emdedding_dim, input_length=sequence_length))\n",
    "lstm_out = 32\n",
    "model.add(Bidirectional(LSTM(lstm_out)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(28, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 16)           440304    \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 64)                12544     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                650       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 28)                308       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 453806 (1.73 MB)\n",
      "Trainable params: 453806 (1.73 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2 ANGOISSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_glove_file = 'glove.6B.200d.txt'\n",
    "num_tokens = vocab_size\n",
    "embedding_dim = 200\n",
    "hits = 0\n",
    "misses = 0\n",
    "embeddings_index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "Converted 22046 words (5472 misses)\n"
     ]
    }
   ],
   "source": [
    "# Read word vectors\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))\n",
    "\n",
    "# Assign word vectors to our dictionary/vocabulary\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2   12  304  277 2233  318  121  530  741    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 200, 200)          6467600   \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirecti  (None, 200, 512)          935936    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirecti  (None, 200, 256)          656384    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirecti  (None, 256)               394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 28)                7196      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8461356 (32.28 MB)\n",
      "Trainable params: 1993756 (7.61 MB)\n",
      "Non-trainable params: 6467600 (24.67 MB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# MODIFS \n",
    "#import Adam\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "adam = Adam(learning_rate=0.005)\n",
    "print(X_train[0])\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 200, input_length=X_train.shape[1], weights=[embedding_matrix], trainable=False))\n",
    "model.add(Bidirectional(LSTM(256, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(28, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 01:00:15.765056: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 98646400 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), verbose=1, epochs=30, batch_size=256, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.getcwd()\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "callback = EarlyStopping(monitor='val_accuracy', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30827, 200)\n",
      "(30827, 28)\n"
     ]
    }
   ],
   "source": [
    "print(test_padded.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 23:49:05.869528: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 98646400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3854/3854 [==============================] - 154s 39ms/step - loss: 4.0785 - accuracy: 0.1697 - val_loss: 4.4208 - val_accuracy: 0.0399\n",
      "Epoch 2/10\n",
      "3854/3854 [==============================] - 151s 39ms/step - loss: 4.5192 - accuracy: 0.1343 - val_loss: 4.4459 - val_accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "3854/3854 [==============================] - 154s 40ms/step - loss: 4.9040 - accuracy: 0.1184 - val_loss: 5.2836 - val_accuracy: 0.2080\n",
      "Epoch 4/10\n",
      "3854/3854 [==============================] - 155s 40ms/step - loss: 5.2982 - accuracy: 0.1100 - val_loss: 5.0433 - val_accuracy: 0.0637\n",
      "Epoch 5/10\n",
      "3854/3854 [==============================] - 170s 44ms/step - loss: 5.7452 - accuracy: 0.1035 - val_loss: 6.3718 - val_accuracy: 0.2080\n",
      "Epoch 6/10\n",
      "3854/3854 [==============================] - 157s 41ms/step - loss: 6.5096 - accuracy: 0.0969 - val_loss: 6.3591 - val_accuracy: 0.0125\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_padded, y_train, batch_size=32, epochs=10, validation_data=(test_padded, y_test), callbacks=[callback, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   3/3854 [..............................] - ETA: 2:32 - loss: 5.2912 - accuracy: 0.1042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 00:11:28.664410: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 98646400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3854/3854 [==============================] - 156s 41ms/step - loss: 7.3180 - accuracy: 0.0929 - val_loss: 10.1639 - val_accuracy: 0.0448\n",
      "Epoch 2/10\n",
      "3854/3854 [==============================] - 152s 40ms/step - loss: 8.1766 - accuracy: 0.0874 - val_loss: 12.4928 - val_accuracy: 0.0286\n",
      "Epoch 3/10\n",
      "3854/3854 [==============================] - 154s 40ms/step - loss: 9.6635 - accuracy: 0.0850 - val_loss: 11.0075 - val_accuracy: 0.0263\n",
      "Epoch 4/10\n",
      "3854/3854 [==============================] - 154s 40ms/step - loss: 11.1880 - accuracy: 0.0826 - val_loss: 12.1680 - val_accuracy: 0.0091\n"
     ]
    }
   ],
   "source": [
    "history_2 = model.fit(train_padded, y_train, epochs=10, validation_data=(test_padded, y_test), callbacks=[callback, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       loss  accuracy  val_loss  val_accuracy\n",
      "0  4.078550  0.169681  4.420794      0.039900\n",
      "1  4.519217  0.134330  4.445879      0.019269\n",
      "2  4.903979  0.118354  5.283594      0.208032\n",
      "3  5.298248  0.110050  5.043281      0.063678\n",
      "4  5.745231  0.103505  6.371756      0.208032\n",
      "5  6.509627  0.096896  6.359070      0.012521\n"
     ]
    }
   ],
   "source": [
    "metrics = pd.DataFrame(history.history)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 515ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "{'admiration': 0.03583611, 'amusement': 0.036295306, 'anger': 0.03539889, 'annoyance': 0.035249937, 'approval': 0.035497133, 'caring': 0.035283513, 'confusion': 0.03598936, 'curiosity': 0.035697512, 'desire': 0.035772704, 'disappointment': 0.035457592, 'disapproval': 0.03574583, 'disgust': 0.036047738, 'embarrassment': 0.035823595, 'excitement': 0.036193833, 'fear': 0.03577055, 'gratitude': 0.03547332, 'grief': 0.035599086, 'joy': 0.035447415, 'love': 0.03609365, 'nervousness': 0.035511676, 'optimism': 0.036054898, 'pride': 0.035290435, 'realization': 0.035785846, 'relief': 0.035828557, 'remorse': 0.0359544, 'sadness': 0.035596345, 'surprise': 0.035421625, 'neutral': 0.0358831}\n",
      "['amusement', 'excitement', 'love']\n"
     ]
    }
   ],
   "source": [
    "#test prediction\n",
    "text = [\"I hate you\"]\n",
    "text_seq = tokenizer.texts_to_sequences(text)\n",
    "text_padded = pad_sequences(text_seq, maxlen=sequence_length, padding='post', truncating='post')\n",
    "# print(text_padded)\n",
    "# print(model.predict(text_padded))\n",
    "#show emotions with it prediction value\n",
    "# print(df_go.columns[1:])\n",
    "# print(model.predict(text_padded))\n",
    "\n",
    "#Show the 3 max emotions\n",
    "# print(df_go.columns[1:])\n",
    "# print(model.predict(text_padded).argsort()[-3:][::-1])\n",
    "\n",
    "\n",
    "#Create a dictionary with all the emotions and values\n",
    "dict = {}\n",
    "for i in range(len(df_go.columns[1:])):\n",
    "    dict[df_go.columns[i+1]] = model.predict(text_padded)[0][i]\n",
    "\n",
    "print(dict)\n",
    "#Show the 3 max emotions\n",
    "print(sorted(dict, key=dict.get, reverse=True)[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flo/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#save the model\n",
    "model.save('emotion_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üò†\n"
     ]
    }
   ],
   "source": [
    "#Make a dictionnary make a smiley associated to each emotion\n",
    "dict_smiley = {'anger': 'üò†', 'annoyance': 'üòí', 'anticipation': 'üò¨', 'disapproval': 'üòñ', 'disgust': 'ü§¢', 'fear': 'üò®', 'joy': 'üòÇ', 'love': 'üòç', 'optimism': 'üòÉ', 'pessimism': 'üòî', 'sadness': 'üò¢', 'surprise': 'üòÆ', 'trust': 'üòá'}\n",
    "print(dict_smiley['anger'])\n",
    "#From a sentence return the 3 smileys associated to the 3 max emotions\n",
    "def predict_emotion(text):\n",
    "    text_seq = tokenizer.texts_to_sequences(text)\n",
    "    text_padded = pad_sequences(text_seq, maxlen=sequence_length, padding='post', truncating='post')\n",
    "    dict = {}\n",
    "    for i in range(len(df_go.columns[1:])):\n",
    "        dict[df_go.columns[i+1]] = model.predict(text_padded)[0][i]\n",
    "    dict = {k: v for k, v in sorted(dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return [dict_smiley[x] for x in list(dict.keys())[:3]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
